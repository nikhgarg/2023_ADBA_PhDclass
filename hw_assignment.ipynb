{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stan\n",
    "\n",
    "import nest_asyncio # https://pystan.readthedocs.io/en/latest/faq.html\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload packages from notebook whenever needed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import arviz as az # For visualization and loo\n",
    "import seaborn as sns "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you're going to go through an exercise in going from a problem description, to writing down a statistical model, to fitting it both using raw Python and in Stan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**: We have two independent variables (covariates), $x1$ and $x2$, and two unknown latent parameters $\\alpha$ and $\\beta$. The independent data $y$ is generated as follows. First, a coin is flipped and if it is heads, then $y = 0$. Otherwise, $y$ is drawn according to a Poisson random variable. This is typically called a \"zero-inflated Poisson\" model. \n",
    "\n",
    "The coin flip is heads with probability $logit^{-1}(\\alpha x_1)$. The Poisson random variable has rate $e^{\\beta x_2}$. \n",
    "\n",
    "Our prior is that $\\alpha, \\beta$ are both drawn from a uniform random variable between -1 and 1. The covariates are both drawn from a Normal distribution with mean 0 and variance 1. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual: Describe a research setting that conceivably corresponds to this data generating process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the statistical model down in math.\n",
    "In other words, what are the distributions from which $x_1, x_2, \\alpha, \\beta, y$ are sampled?\n",
    "\n",
    "Either using LaTeX within markdown, or inserting an image with math into the markdown. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data from the true model, given fixed parameters $\\alpha, \\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import bernoulli, norm, poisson\n",
    "\n",
    "def inv_logit(v):\n",
    "    return 1/(1+np.exp(-v))\n",
    "\n",
    "# TODO finish this function\n",
    "# the output should be a dataframe with columns x1, x2, y\n",
    "def generate_data(theta, N):\n",
    "    alpha, beta = theta #as in lecture, theta = (alpha, beta)\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_data(df):\n",
    "    sns.histplot(df.y)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    cuts = pd.DataFrame({str(feature) + 'Bin' : pd.qcut(df[feature], 5) for feature in ['x1', 'x2']})\n",
    "    dfplot = pd.concat([df, cuts], axis=1)[['y', 'x1Bin', 'x2Bin']].groupby(['x1Bin', 'x2Bin']).mean().reset_index()\n",
    "    dfpivot = dfplot.pivot(index='x1Bin', columns='x2Bin', values='y')\n",
    "    plt.clf()\n",
    "    sns.heatmap(dfpivot) \n",
    "    plt.title('Means of y vs Features x1 and x2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below will plot the data once you have filled out the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = (1, 1)\n",
    "df = generate_data((alpha, beta), 1000)\n",
    "plot_generated_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = (.5, -1)\n",
    "df = generate_data((alpha, beta), 1000)\n",
    "plot_generated_data(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate posterior using your own code\n",
    "\n",
    "As we did in Lecture 2 and Lecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior for alpha, beta from the statistical model\n",
    "\n",
    "#TODO finish this function for the pdf of theta. Hint: what is the area of the rectangle from -1 to 1 in both dimensions?\n",
    "def p_theta(theta):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# TODO finish this function for P({y} | theta, {x1}, {x2})\n",
    "# Bonus: do this in log space to avoid underflow\n",
    "def p_data_given_theta(theta, data, do_log = False):\n",
    "    alpha, beta = theta\n",
    "    ys = data['y']\n",
    "    \n",
    "    #TODO finish this function for P(y | theta, x1, x2)\n",
    "    # Hint: there are 2 cases, y_i = 0 and y_i > 0\n",
    "    # Hint: you'll use the inv_logit function defined above\n",
    "    # Hint: you'll use the poisson distribution from scipy.stats, and the pmf method of the poisson distribution\n",
    "    def single_y_likelihood(y, x1, x2):\n",
    "        pass\n",
    "    \n",
    "    vals = [single_y_likelihood(y, x1, x2) for y, x1, x2 in zip(ys, data['x1'], data['x2'])]\n",
    "    data['vals'] = vals\n",
    "    \n",
    "    # TODO finish below\n",
    "    if not do_log:\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# TODO finish this function for P(y | x1, x2)\n",
    "# bonus: do this in log space to avoid underflow\n",
    "def p_data(data, possible_theta_values, do_log = False):\n",
    "    \"\"\"\n",
    "    This function is the marginal likelihood of the data.\n",
    "    It is the integral of the likelihood function over possible values of theta, weighted by the prior.\n",
    "    \"\"\"\n",
    "    if not do_log:\n",
    "        pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO finish this function to sample possible_theta_values, p_theta_given_data using grid sampling\n",
    "# bonus: do this in log space to avoid underflow\n",
    "def grid_sampling(data, gridnum = 1000, do_log = False):\n",
    "    possible_alpha_values = np.linspace(-1, 1, gridnum)\n",
    "    possible_beta_values = np.linspace(-1, 1, gridnum)\n",
    "    possible_theta_values = [(alpha, beta) for alpha in possible_alpha_values for beta in possible_beta_values]\n",
    "\n",
    "    #TODO finish \n",
    "    p_theta_given_data = None\n",
    "\n",
    "    return possible_theta_values, p_theta_given_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_alpha, true_beta = (.25, .5)\n",
    "df = generate_data((true_alpha, true_beta), 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below will plot posterior for alpha, beta using grid sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_theta_values, p_theta_given_data = grid_sampling(df, gridnum = 10)\n",
    "dfplot = pd.DataFrame(possible_theta_values, columns=['alpha', 'beta'])\n",
    "dfplot['p_theta_given_data'] = p_theta_given_data\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "sns.heatmap(dfplot.pivot('alpha', 'beta', 'p_theta_given_data'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Below will plot log posterior for alpha, beta using grid sampling in log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_theta_values, p_theta_given_data = grid_sampling(df, gridnum = 10, do_log=True)\n",
    "dfplot = pd.DataFrame(possible_theta_values, columns=['alpha', 'beta'])\n",
    "dfplot['log_p_theta_given_data'] = p_theta_given_data\n",
    "sns.heatmap(dfplot.pivot('alpha', 'beta', 'log_p_theta_given_data'))\n",
    "plt.title('log_p_theta_given_data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In log space, can do with larger datasets without underflow (though P(data) is still troublesome...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_alpha, true_beta = (.25, .5)\n",
    "df = generate_data((true_alpha, true_beta), 500)\n",
    "possible_theta_values, p_theta_given_data = grid_sampling(df, gridnum = 10, do_log=True)\n",
    "dfplot = pd.DataFrame(possible_theta_values, columns=['alpha', 'beta'])\n",
    "dfplot['log_p_theta_given_data'] = p_theta_given_data\n",
    "sns.heatmap(dfplot.pivot('alpha', 'beta', 'log_p_theta_given_data'))\n",
    "plt.title('log_p_theta_given_data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more data points, we get much tighter posteriors (observe the color scale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, fit a Stan model for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_alpha, true_beta = (.25, .5)\n",
    "df = generate_data((true_alpha, true_beta), 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, just fit a Poisson regression, ignoring the zero inflation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll fit a \"mis-specified\" model -- suppose we just fit a Poisson regression, i.e.:\n",
    "\n",
    "\\begin{align*}\n",
    "    y &\\sim Poisson (e^{intercept + \\alpha*x_1 + \\beta*x_2})\n",
    "\\end{align*}\n",
    "The following will be useful: https://mc-stan.org/docs/functions-reference/poisson-log-glm.html. You'll likely need to directly increment the `target` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_data = {'N': df.shape[0], 'y': df.y.values, 'X': df[['x1', 'x2']].values}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: write a Stan model and save it in poissonregression.stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_folder = './'\n",
    "stan_file = stan_folder + 'poissonregression.stan'\n",
    "with open(stan_file) as file:\n",
    "    model_code = file.read()\n",
    "print(model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = stan.build(model_code, data=stan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = compiled_model.sample(num_chains=2, num_warmup = 100, num_samples= 500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote some of the code for you to analyze the model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = az.from_pystan(posterior=fit, posterior_model=compiled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = az.summary(fit)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fit, compact=False, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: In your poissonregression.stan file, use the generated quantities block to sample \n",
    "# from the posterior predictive distribution and plot the posterior predictive distribution here.\n",
    "# Display it in the same plot as the true $y$ data, and comment on comparing the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO bonus: use arviz to plot the posterior predictive distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, fit a correct Stan model reflecting the true data generating process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit a zero inflated Poisson in stan.\n",
    "\n",
    "Hint: you'll need to directly increment the `target` parameter.\n",
    "\n",
    "Hint: you'll likely need the following functions: `log_sum_exp`, `bernoulli_logit_lpmf`, `poisson_log_glm_lpmf`\n",
    "\n",
    "Hint: I had to play around a bit with the input parameter formatting (e.g., put x2 inside its own matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_folder = './'\n",
    "stan_file = stan_folder + 'zeroinflatedpoisson.stan'\n",
    "with open(stan_file) as file:\n",
    "    model_code = file.read()\n",
    "print(model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = stan.build(model_code, data=stan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = compiled_model.sample(num_chains=2, num_warmup = 100, num_samples= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = az.from_pystan(posterior=fit, posterior_model=compiled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = az.summary(fit)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fit, compact=False, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: As before, In your stan file, use the generated quantities block to sample \n",
    "# from the posterior predictive distribution and plot the posterior predictive distribution here.\n",
    "# Display it in the same plot as the true $y$ data, and comment on comparing the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) \n[GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23e00de46872ae4b7c229dc8f952d4187d8a81a3080d6c890f7986816b8346cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
